	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/asfarley--" target="_blank">asfarley--</a>
			<div class="markdown"><p>Dedekind was a mathematician, not a neuroscientist; my experience has been that mathematicians and physicists (Penrose) tend to give consciousness or human intuition more weight than it deserves.</p>
<p>My guess about the 'lightbulb' moment is that this is <em>not</em> a flood of emotions or dopamine; it's probably more like a 'conflict-resolution-cascade' where you suddenly fix several misunderstandings. The feeling here would be more like relief from mental tension.</p>
<p>One view of belief-networks (including neural networks) is that they are identifying a most-likely wordview which corresponds with a 'potential energy minimum'. So, your brain is jumping from a high-tension, conflicting worldview to a low-tension, self-consistent worldview.</p>
<p>Let me make a distinction. I agree that there is some dopamine reward associated with learning. However, I think the 'lightbulb moment' is neurologically distinct from general positive rewards associated with learning. I think that 'lighbulb moment' suggests a moment of rapid illumination where several questions become clarified at once, rather than becoming aware of a single fact in isolation.</p>
<p>Besides, what you're doing here by claiming that human intuition can't be replicated is pegging your claims to a currently-unachieved AI milestone. Historically, whenever people do this, they turn out to be wrong a few years later. If we develop an AI that can pass the turing test, it seems to me that this would invalidate your claims about the finiteness of logic.</p>
<p><code>logic with infinitely many truth values. There is no known way of doing this</code></p>
<p>Fuzzy logic with 32-bit floats. Not a problem in practice at all.</p>
<p><strong>Direct answer to OP's question:</strong></p>
<p>Modern neuroscience <em>does not know exactly</em> how neurons change at a physical level to allow learning. Some theories include growing more dendrites/connections to other neurons, or changing how strong those connections are by adjusting the amount of neurotransmitter at the junctions. You have encountered an open question!</p>
<p>I once worked on a project that attempted to interface neurons with silicon using laser bursts. I asked my advisor how to measure inter-neuron weights. He laughed, and told me that neuroscientists don't even try to do that.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/internet_user1013" target="_blank">internet_user1013</a>
			<div class="markdown"><p>There is a distinction between the dopamine you get from learning, and the endorphins released when you suddenly grok some topic. They activate different sets of receptors. </p>
<p>As for the infinitary logic, I didn't say it was impossible, just that we didn't know how yet. Fuzzy logic in my opinion is approximating an infinitary logic, but it still relies on a finite number of parameters, and finite precision. Perhaps the answer lies in quantum computing, where a superposition can represent all states at once. Maybe at a certain number of qubits, the representation is so large that we can no longer make a distinction between infinite sets and these.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/asfarley--" target="_blank">asfarley--</a>
			<div class="markdown"><blockquote>
<p>endorphins released when you suddenly grok some topic </p>
</blockquote>
<p>I wasn't aware of this; is this from recent research? </p>
<blockquote>
<p>at a certain number of qubits, the representation is so large that we can no longer make a distinction </p>
</blockquote>
<p>But this is true for regular ol' neuron spikes as well too. Why is it necessary to introduce superposition?</p>
<p>Who says that we need anything beyond simple hardware to perform calculations? Computers execute symbolic algebra (including the infinity sign) using finite, binary logic. What does the issue of representing infinity have to do with the underlying hardware? </p>
<p>It seems to me that (based on symbolic algebra) it's relatively easy to encode the concept of infinity into a finite space.</p>
<p>While we're at it, I think it's important to distinuish what types of state-spaces can be represented by quantum bits vs. discrete bits. Sure, they are continuous, but that doesn't mean e.g. the state-space of 2 quantum bits spans the entire representation of our world. Quantum representations may still be incomplete approximations. So why is it such a big deal whether we're embedding our high-dimensional-space of observations into a discretized pulse-train or a continuous quantum state? They are both approximations.</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/bigfish42" target="_blank">bigfish42</a>
			<div class="markdown"><p>Okay, now ELI5</p></div>		</li>
					</ul>
	
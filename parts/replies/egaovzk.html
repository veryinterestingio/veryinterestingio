	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/AraShir0" target="_blank">AraShir0</a>
			<div class="markdown"><p>So we're close to the physical limit of miniaturization, in theory? Is Moore's law still true in the last years?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ManaSpike" target="_blank">ManaSpike</a>
			<div class="markdown"><p>We haven't kept up with Moore's law in terms of transistor size for a while now. Each time we shrink the transistor, it gets more expensive to design and build the process that creates them. Plus now, I believe, we're getting close to the point where the fuzzy nature of electrons allows them to jump over gaps between transistors. </p>
<p>Plus there's only so many transistors that you need inside a single CPU core anyway. So most recent CPU improvements have been about doing more calculations in parallel. From simple changes like putting multiple complete CPU's onto the same chip so multiple programs, or copies of programs, can run at once. To adding new instructions so a program can process a whole array of values at once.</p>
<p>If you have an x86/x64 Intel/AMD CPU, the instructions of a programs aren't really what the core of the CPU really runs. A huge number of transistors in a modern Intel CPU are devoted to translating these instructions into the real instructions that the CPU core executes. It's like there's a whole other type of computer inside your CPU that is pretending to be the same old design as the late 90's.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/glaive_anus" target="_blank">glaive_anus</a>
			<div class="markdown"><p>To add, for day to day computing we've hit the point whereby additional speed and performance isn't quite that impactful anymore. In the very late 1990s / early 2000s, year to year performance upgrades are pretty notable for computing as software demands from hardware grew. Nowadays, the largest majority of users can still get by with their day to day needs with chipsets 3-4++ years old. </p>
<p>Energy efficiency, miniaturization, and hardware specificity are also pretty important topics to focus on now. </p>
<p>For example, it's common consensus that Apple's ARM chips in their iPhones and iPads are much more powerful than their counterparts on same-generation Android products in recent years, but it's likely that the future years' discussion will be dominated by the strength of dedicated neural network hardware in these same products, and how they leverage this for features and functions.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ChrisFromIT" target="_blank">ChrisFromIT</a>
			<div class="markdown"><blockquote>
<p>Plus now, I believe, we're getting close to the point where the fuzzy nature of electrons allows them to jump over gaps between transistors. </p>
</blockquote>
<p>I think you mean the gates, since the gates are where most of the shrinking happens.</p>
<p>And we have already passed that point. These days, CPU no longer work on the current is on and the current is off, because of leaks in the gates due to quantum tunneling and spooky science there is always a current. So CPUs use low voltage and high voltages as instead of the current being off or on.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/RJrules64" target="_blank">RJrules64</a>
			<div class="markdown"><p>Really? I swear I’ve seen a graph of Moore’s law labelled with different CPUs along the straight line on an exponential axis.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/michellelabelle" target="_blank">michellelabelle</a>
			<div class="markdown"><p>We are somewhat close to the physical limit of miniaturization, considering that we started with vacuum tubes the size of your forearm, but more because of quantum tunneling and other more mundane forms of leakage borking things than speed of light considerations. (This is a huge oversimplification; there are other practical issues too.)</p>
<p>Don't get me wrong, there are lots of ways to improve overall computer speed, and many of them are not nearly as tapped out as ultra-super-hyperfine engraving of transistors. IDK if chips will be where Moore's &quot;law&quot; says it will be in ten years, but there'll be more transistors packed in there than we have today.</p>
<p>Whether anyone has a particularly good use for such chips, as opposed to a bunch of mere 2019-quality chips strung together, is a different question.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/A_Garbage_Truck" target="_blank">A_Garbage_Truck</a>
			<div class="markdown"><p>it's one of the reason why there is a bigger interest in quantum computing now.</p>
<p>CPUs as we known them now are starting ot hit a physical limit due to just how muhc you can further improve the manufacturing process(10 to 7 nm is already giving researchers  alot of crap with current leakage and your signal just stragiht up ignoring the barriers you set for them with the circuit paths).</p>
<p>moore's law hasnt been holding out too well but its not entirely invalid yet, it just slowed down significantly since the major manufacturers dont have  have a relaiable means o tmanufacture a faster Cpu.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/SoManyTimesBefore" target="_blank">SoManyTimesBefore</a>
			<div class="markdown"><blockquote>
<p>it's one of the reason why there is a bigger interest in quantum computing now.</p>
</blockquote>
<p>Quantum computers are used for solving a completely different set of problems than regular CPUs.</p>
<p>&#x200B;</p>
<blockquote>
<p>moore's law hasnt been holding out too well but its not entirely invalid yet, it just slowed down significantly since the major manufacturers dont have have a relaiable means o tmanufacture a faster Cpu.</p>
</blockquote>
<p>It's not a moore's law anymore then. Since the definition is that the number of transistors in an integrated circuit doubles every 2 years.</p>
<p>&#x200B;</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Flyron" target="_blank">Flyron</a>
			<div class="markdown"><p>Iirc, the electrons travel rather slowly through the wiring. But one moving electron pushes the next and so you have a wave of movement of electrons going through the cable, the electric signal, that's moving close to the speed of light.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/teebob21" target="_blank">teebob21</a>
			<div class="markdown"><blockquote>
<p>That is as far as an electronics signal could travel (roundtrip) in the CPU in during one cycle under the best of circumstances. (Obviously the circumstances aren't the best.)</p>
</blockquote>
<p>The term you are looking for is <a href="https://www.scte.org/TechnicalColumns/10-03-01%20velocity%20of%20propagation.pdf" target="_blank">velocity of propagation</a>. I don't know the VOPs for electrons in silicon off the top of my head, but light averages about 0.67c in fiber optic cables, and RF travels about 0.85c in coax.</p></div>		</li>
					</ul>
	
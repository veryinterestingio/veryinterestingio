	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/EchinusRosso" target="_blank">EchinusRosso</a>
			<div class="markdown"><p>And then, you can further compress the data by just saying &quot;beans and soup.&quot; Some data is lost in this case, you no longer have the quantities, but for most use cases you probably don't need the quantity anyway, such as if you were looking for canned pineapples.</p>
<p>Audio/video compression almost always means data loss, but tends to focus on data which won't impact the enduser experience</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/johnothetree" target="_blank">johnothetree</a>
			<div class="markdown"><p>Don't tell the audiophiles you said this</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Thelllooo" target="_blank">Thelllooo</a>
			<div class="markdown"><p>Me, working in the audiophile industry selling boxes and wires that make wavy air sound &quot;better&quot;.</p>
<p>Haha paycheck go brrrrrrrrr</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Somegeezer" target="_blank">Somegeezer</a>
			<div class="markdown"><p>Audiophiles don't use compression algos that are lossy. They will spend a bajillion money on a cable that makes no difference to a digital signal from a 1 money cable. But that's another matter.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/sodaextraiceplease" target="_blank">sodaextraiceplease</a>
			<div class="markdown"><p>Yeah. Cymbals and high hats somehow get compressed as a babbling brook.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/could_use_a_snack" target="_blank">could_use_a_snack</a>
			<div class="markdown"><p>Not sure if this is still a thing, but at one point there was experimental video compression that would compress the edges of frames more than the center. The idea being that's where the important information is.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/GalaxyMods" target="_blank">GalaxyMods</a>
			<div class="markdown"><p>That actually seems incredibly smart. Do you happen to remember the name of this encoding method?</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/SudoBoyar" target="_blank">SudoBoyar</a>
			<div class="markdown"><p><a href="https://www.google.com/search?q=foveated+rendering" target="_blank">Foveated rendering</a> is a similar idea for games, may have been inspired by that</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/KingKlob" target="_blank">KingKlob</a>
			<div class="markdown"><p>Thatbis definitely still a thing. If you look at just say youtube you can see where there should be a solid background it looks more like a gradient background. That is because of the compression, its not exactly what you are talking about but its the same idea. Compress the not so important parts and leave the important parts the same</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Recoil42" target="_blank">Recoil42</a>
			<div class="markdown"><p>Great explanation. Because I'm a completionist, this kind of compression is called <strong>lossy compression</strong>, whereas the other kind (no information lost) is called <strong>lossless compression</strong>.</p>
<p>Double completionism: You can choose which things you lose and which ones you keep! What if I just said &quot;7 food cans&quot; instead of &quot;beans and soup&quot;? Less precise in one way (type of food), but more precise in another (quantity).</p>
<p>How does this relate? Well, in video files, for instance, we encode information about what objects should be on screen, what colours they are, <em>and</em> which direction they're travelling in. You can tweak for things like colour accuracy, positional accuracy, and amount of detail. When we misstep on those things — like when you see blockiness and jittering in the satellite feed for a soccer game — it's called <strong>artifacting</strong>, and those errors are called <strong>artifacts</strong>.</p>
<p>A whole art form surrounding intentionally introducing different types of artifacting exists called <strong>datamoshing</strong>. Examples can be seen at r/datamoshing, or perhaps most notably, the totally wonderful music video for Kanye West's <a href="https://www.youtube.com/watch?v=wMH0e8kIZtE" target="_blank">Welcome to Heartbreak</a>.</p>
<p>If you'd like to go deeper, <a href="https://en.wikipedia.org/wiki/Video_compression_picture_types" target="_blank">start here.</a></p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/mdgraller" target="_blank">mdgraller</a>
			<div class="markdown"><blockquote>
<p>like when you see blockiness and jittering in the satellite feed for a soccer game — it's called artifacting, and those errors are called artifacts</p>
</blockquote>
<p>Or on YouTube when you see a dark or mostly-black screen and you see those obvious black boxes clanging into one another</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/KverEU" target="_blank">KverEU</a>
			<div class="markdown"><p>Depending on what you're doing with the files (i.e. moving) your OS also treats them differently. Try moving those cans in one go rather than individually. It's heavier but takes less time.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Curse3242" target="_blank">Curse3242</a>
			<div class="markdown"><p>So technically with super fast SSDs and advancements in tech. Can we in future see super small sizes for large amounts of data. Like without compression?</p>
<p>What if we go back to the days where 64 mb of memory was enough</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/mwclarkson" target="_blank">mwclarkson</a>
			<div class="markdown"><p>Sadly not. This is still compression, just lossless rather than lossy. Sadly it rarely lines up that you can make huge savings this way, which is why a zip file is only slightly smaller than the original in most cases. </p>
<p>The order of the data is critical. So Beans - Soup - Beans couldn't be shortened to 2xBeans-1xSoup.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/fiskfisk" target="_blank">fiskfisk</a>
			<div class="markdown"><p>Instead it could be shortened to a dictionary, <code>1: Beans, 2: Soup</code> and then the content: <code>1 2 1</code>.</p>
<p>If you had <code>Beans Soup Beans Soup Beans Soup Beans Soup</code>, you could shorten it to <code>1: Beans Soup, 1 1 1 1 or 4x1</code></p>
<p>A (lossless) compression algorithm are generally ways to find how some values could be replaced with other values and still retain the original information.</p>
<p>Another interesting property is that (purely) random data is not compressible (but you specific cases of random data could be).</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/MichaelCasson" target="_blank">MichaelCasson</a>
			<div class="markdown"><p>The difference in sizes between zip files and the files they contain depends a lot on what those files are. If it's a bunch of text logs or documents, they might compress very well. But if they are files types that already include their own compression (mp3, jpg, mp4), then they will not compress much if at all.</p>
<p>Sometimes zip files are handy for just grouping a bunch of files together, with subfolders, for transport/download even if they don't compress much.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/TheHYPO" target="_blank">TheHYPO</a>
			<div class="markdown"><blockquote>
<p>which is why a zip file is only slightly smaller than the original in most cases.</p>
</blockquote>
<p>This is more commonly because so many of the files we use these days are already some-level-of compressed.</p>
<p>MP3s won't zip much smaller than they already are, but you can zip wav files with some reasonable gains (though not as much gain as MP3 which is both tailored for music and sacrifices some data for filesize)</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/sy029" target="_blank">sy029</a>
			<div class="markdown"><p>Not really. Compression isn't infinite. If I said &quot;AAAAAABBBBBBB&quot; you can shrink it down to &quot;6A7B&quot; But past that, there's nothing you could do to make it smaller.</p>
<p>(Technically there are ways to make the above even smaller, but the point is that at some point you will hit a limit.)</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/MCH2804" target="_blank">MCH2804</a>
			<div class="markdown"><p>Just curious, how can you make the above even smaller</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/mfanter" target="_blank">mfanter</a>
			<div class="markdown"><p>Can’t you represent it as 1111110000000 which would be 13 bits whereas
6A7B is 16 bits? </p>
<p>It gets more complicated when the order isn’t known - for example what about AABBAB
1A2B1A1B is longer. </p>
<p>Hoffman’s algorithm can get the optimal presentation in binary bits of letters based on their frequency.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/a_cute_epic_axis" target="_blank">a_cute_epic_axis</a>
			<div class="markdown"><p>It depends.  In commercial storage data deduplication is common.  Imagine you have a virtual environment for 100 people with windows machines... And they all get some group emails, and they all have some common corporate documents and data.  You really only need to store one copy of the operating system, a list of who has it, and then the files and emails unique to each person.  For every person that has an unmodified copy of an email or file, you only have to store wit once.</p>
<p>If 50 people go to the Reddit home page or CNN or the local weather, you can cache the common data, especially graphics, so you only send that data across the network the first time someone requests in in a day, or whenever it changes.</p></div>		</li>
					</ul>
		</ul>
	
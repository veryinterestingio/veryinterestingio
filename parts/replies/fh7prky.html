	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/IdonTknow1323" target="_blank">IdonTknow1323</a>
			<div class="markdown"><p>Graduate student in software engineering here, professional worker in this field for several years üëã
A good analogy I was once told was:</p>
<p>A CPU is like one very advanced man doing a lot of calculations.
A GPU is like a ton of very dumb men who can each do very simple calculations. </p>
<p>Put them together, and you can have the CPU deal with all the heavy back-end stuff and reads/writes, then the GPU deal with the graphics who have to draw a bunch of pixels to the screen</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ElectronicGate" target="_blank">ElectronicGate</a>
			<div class="markdown"><p>Maybe a slight refinement: a CPU is a small group of workers (cores) with highly diverse skills who can work on different, unrelated tasks simultaneously. A GPU is a large group of workers all given identical instructions to perform a task, and each are given a tiny piece of the overall input to perform the task on simultaneously.  GPUs are all about &quot;single instruction, multiple data&quot; computation.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Gnarmoden" target="_blank">Gnarmoden</a>
			<div class="markdown"><p>A much stronger analogy.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Gnarmoden" target="_blank">Gnarmoden</a>
			<div class="markdown"><p>I'm not all that certain this is a good analogy. As the author of the post said above, neither unit is smarter or dumber than the other. Both can solve tremendously complicated tasks. I will avoid continuing to explain the differences and defer to the other top levels posts that are being highly upvoted.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/toastee" target="_blank">toastee</a>
			<div class="markdown"><p>Actually, a GPU gets its advantage from being &quot;dumber&quot; a GPU supports a limited number of op codes, and some things are just impractical.</p>
<p>But for the stuff it does support, it and it's 1023+ retarded brothers in the GPU core can do it hella fast, and massively parallel.</p>
<p>Sure the CPU can make the same call and calculate the same data, but if it's a task the GPU can paralellise the the GPU is going to win.</p>
<p>Fun fact, if you have a shitty enough video card and a fast enough CPU, you can improve frame rate by switching to CPU based rendering.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/IdonTknow1323" target="_blank">IdonTknow1323</a>
			<div class="markdown"><p>If each of the tiny men in your GPU are smarter than your one CPU, you're way overdue for an upgrade. Therefore, I don't retract my statement.</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/saptarshighosh" target="_blank">saptarshighosh</a>
			<div class="markdown"><p>Your comment is probably the most in-depth yet simpler explanation. Fellow developer here.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Fysco" target="_blank">Fysco</a>
			<div class="markdown"><p>Thanks, at the time I wrote it, a lot of wrong information was being upvoted like crazy. I felt I had to share some realness lol.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/saptarshighosh" target="_blank">saptarshighosh</a>
			<div class="markdown"><p>Yup. I saw lots of that. üòÅ</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Foempert" target="_blank">Foempert</a>
			<div class="markdown"><p>I'd just like add one thing: <strong>theoretically</strong>, ray tracing is more efficient than rasterization based rendering, given that the amount of polygons is vastly greater than the amount of pixels in the image. This is definitely the case in the movie industry (not so sure about games, but that's undoubtedly coming).<br />
What I'd like to see is the performance of a GPU with <em>only</em> ray tracing cores, instead of a heap of normal compute cores, with hardware ray tracing added to the side.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Fysco" target="_blank">Fysco</a>
			<div class="markdown"><p>Polygon budget for a game (so,triangles instead of quads) anno 2020 is about 3-5 million per frame. Depending on who you ask offc. A rendering engineer will answer &quot;as few as possible please&quot;. An artist will answer &quot;the more the better&quot;.</p>
<p>So in terms of poly count, yes, movie CGI and VFX go for realism and they render offline. Polycount is less of an issue (but still a thing).</p>
<p>The shaders in VFX are also way more expensive to render than a game shader. Game humans and trees have more of a 'plastic' or 'paper' feel to them, due to the shaders not being stuffed to the rafters with info and maps. Shaders in games need to be fast.</p>
<p>Just to compare; here is a mesh model with Octane shader materials and offline raytracing rendering I did recently: <a href="https://i.redd.it/d1dulaucg4g41.png" target="_blank">https://i.redd.it/d1dulaucg4g41.png</a></p>
<p>And here is the same mesh model with game engine shaders in realtime non-RT (DL) rendering: <a href="https://imgur.com/a/zhrWPdu" target="_blank">https://imgur.com/a/zhrWPdu</a></p>
<blockquote>
<p>theoretically, ray tracing is more efficient than rasterization based rendering, given that the amount of polygons is vastly greater than the amount of pixels in the image.</p>
</blockquote>
<p>Which is true IF you want realism and IF you have the hardware to back it up. I believe realtime RT is the 2020's vision for realtime 3D and it will propel us forward in terms of graphics. I'm happy Microsoft, Nvidia and AMD are taking first steps to enable artists and engineers to do so.</p></div>		</li>
					</ul>
		</ul>
	
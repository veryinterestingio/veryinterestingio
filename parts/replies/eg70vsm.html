	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Automatic_Towel" target="_blank">Automatic_Towel</a>
			<div class="markdown"><p>A couple confusing things.</p>
<blockquote>
<p>given that smoking doesn't makes us live longer, we will still see a connection between smoking and a long life 5% of the time</p>
</blockquote>
<p>I think it's the case that you will observe a connection <em>at most</em> 5% of the time, which is what would happen if smoking had no effect on life expectancy. But granting that smoking has a negative effect on life expectancy, I think you will reject the null less than 5% of the time.</p>
<hr />
<blockquote>
<p>we make a conclusion by rejecting the null hypothesis, or being able to confidently say that the opposite of our study's assumption is NOT true</p>
<p>[...]</p>
<p>A P-value cannot tell us how confident we are that we got the &quot;right&quot; results</p>
</blockquote>
<p>I think the use of 'confidence' in these two places is inconsistent. If confidence is defined in terms of statistical significance (i.e., false positive rate control), then it does tell us how confident we are in a rejection of the null. If you're using it as synonymous with how likely it is that the null is true (posterior probability), then it's not the case that we're &quot;confident&quot; that the null is false when we reject the null.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Ufarious" target="_blank">Ufarious</a>
			<div class="markdown"><p>A couple things to clarify:</p>
<ol>
<li>The example I provided was undeniably contrived to illustrate the principle behind a P-Value. I picked a test where we all knew the null was true (&quot; smoking does not make you live longer&quot;) to help illustrate what the P-Value does and does not tell us. That felt appropriate given that this is ELI5. In most studies (except maybe those funded by the smoking lobby), we don't actually know that the null is true -- that's why we are running a test. </li>
<li>Similarly, I simplified the outcome of the experiment to be binary. For that reason, it's a little confusing, but the principles are the same. </li>
<li>A P-Value is not the same thing as an alpha. Alpha is the significance level and is set before the experiment (typically at 0.05, but as others have commented, that depends a lot on industry and experiment). A P-Value is a statistic that is derived from our experimental data. So if we have a P-Value of .05, that has nothing to do with what is stated in the hypothesis or null hypothesis; it is an artifact of the data from the experiment.  <strong>The definition of a P-Value is that it is the probability that we will see results at least as extreme as what we observed GIVEN THAT the null is true.</strong> So it's not that we would observe a connection &quot;at most 5% of the time&quot;, but rather that we would still observe a connection <em>at least as strong as the one we observed</em> 5% of the time <em>given that there is no connection between smoking and living a long life.</em> </li>
<li>Confidence is a tricky word when talking about statistics, due to its use in things like &quot;confidence intervals.&quot; My apologies for the sloppy use here. My underlying points, however, remain true. 
<ol>
<li>In hypothesis testing, we draw conclusions by rejecting the null hypothesis</li>
<li>A P-value cannot tell us the probability that our hypothesis is correct</li>
</ol></li>
</ol>
<blockquote>
<p>If confidence is defined in terms of statistical significance (i.e., false positive rate control), then it does tell us how confident we are in a rejection of the null. </p>
</blockquote>
<p>While a low P-Value suggests that your data are unlikely given that the null is true, it can't help us distinguish between whether the experiment produced this P-Value due to unusual sampling error or a false null. So we can't conclude that a .05 P-Value tells us that there's a 5% chance rejecting the null is wrong. That was what I meant when I wrote, &quot;A P-value cannot tell us how confident we are that we got the &quot;right&quot; results.&quot;</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Automatic_Towel" target="_blank">Automatic_Towel</a>
			<div class="markdown"><p>I don't think the contrived example thing is an issue. Nor the binary outcomeâ€”hypothesis testing is often done in a binary decision framework, right? (Especially if you're firmly in the Neyman-Pearson camp.)</p>
<hr />
<blockquote>
<p>So if we have a P-Value of .05, that has nothing to do with what is stated in the hypothesis or null hypothesis; it is an artifact of the data from the experiment.</p>
</blockquote>
<p>I mean, a p-value is calculated on the assumption of the null hypothesis, which doesn't seem like &quot;nothing to do with.&quot; But if you mean it doesn't give a probability of either hypothesis, then I'm in agreement.</p>
<blockquote>
<p>So it's not that we would observe a connection &quot;at most 5% of the time&quot;, but rather that we would still observe a connection <em>at least as strong as the one we observed</em> 5% of the time <em>given that there is no connection between smoking and living a long life.</em></p>
</blockquote>
<p>Right, I didn't read carefully and since you only said &quot;observe a connection&quot; I thought you were talking about alpha = .05. I think that's a side issue, though.</p>
<p>I think you've also changed from a one-tailed test (smoking makes you live longer) to a two-tailed test (there is a connection between smoking and living a long life). Your original statement is still looking false to me and I'm not sure one how to work things out, formally.</p>
<hr />
<p>re: &quot;confidence&quot;: Yes, your underlying points are much clearer when you don't use the word confidence. In particular, the inconsistent usage could give someone the impression that the null is unlikely to be true when we reject it, we just don't know <em>how</em> unlikely (thus believing they've satisfied the admonition that &quot;a p-value is not the probability the null is true&quot; while partially retaining the fundamental misconception).</p></div>		</li>
					</ul>
		</ul>
		</ul>
	
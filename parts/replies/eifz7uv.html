	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/hosanagar" target="_blank">hosanagar</a>
			<div class="markdown"><p>I do believe that AGI will happen sooner than most lay people believe (but slower than many technologists believe). That is to say within the next 50-60 years. In terms of what happens after, we have 2 possibilities:</p>
<ol>
<li>AGI does everything we could come up with and there's no point in us even trying. Want to cure cancer? If feasible, AGI will beat you to it. So we live well as a result.</li>
<li>AGI takes control and acts in ways we hadn't anticipated. Many people have expressed worries about this.</li>
</ol>
<p>Personally, I belong to neither camp. I think we will have many challenges with AI in the next 10-20 years. Those ill hopefully result in lots of safeguards being put in place. We will likely live in fear that we might lose control but that fear will alone cause many checks and balances to be put in. But i do agree with Elon Musk and many others who were involved in the famous open letter on AI that the concerns are real (<a href="https://en.wikipedia.org/wiki/Open_Letter_on_Artificial_Intelligence" target="_blank">https://en.wikipedia.org/wiki/Open_Letter_on_Artificial_Intelligence</a> ). I am optimistic we'll do the right things along the way to just about keep it under check.</p></div>		</li>
					</ul>
	
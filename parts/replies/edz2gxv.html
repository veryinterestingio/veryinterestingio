	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Im_cereal_" target="_blank">Im_cereal_</a>
			<div class="markdown"><p>Applied AI vs. AGI is the explanation i needed. Because I'm thinking it's all skynet over here.. </p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/halborn" target="_blank">halborn</a>
			<div class="markdown"><p>I thought that might help :)  </p>
<p>To answer the follow-up question you edited in; AI for detecting Alzheimer's disease is actually pretty similar to the 'red versus blue' example I gave above.  Specialists take a picture of the brain using an MRI machine and then the computer mathematically analyses the image for signs of Alzheimer's.  If you have a lot of brain scan images available and you can track patients for a long time (to see whether they eventually develop the disease) then the program may eventually learn to detect signs of the disease that doctors are unaware they should be looking for.  This is why hospital technological infrastructure and the availability of healthcare are important - every patient who can go in and get scanned, every scan you have access to, makes the algorithm more effective and more reliable.  </p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/throwdemawaaay" target="_blank">throwdemawaaay</a>
			<div class="markdown"><p>Yeah. A lot of practitioners prefer the term Machine Learning, as it helps get away from the whole HAL 9000 thing.</p>
<p>To expand on the awesome comment above, most current ML methods can be sorted into two categories: supervised and unsupervised learning. Supervised learning is like the example he gave, where the programmer provides the system a bunch of training data consisting of example inputs, and what the correct output should be. With unsupervised learning, you just hand the system data, and similar statistical cleverness finds similarities and relationships in the data all on its own.</p>
<p>So what does that clever math actually look like? Well, there are a ton of different methods, and lots of researchers rapidly finding new better ones. That said most of them are very similar in that they boil down to multiplying very large matrixes of numbers together. You may have been taught matrix multiplication in an algebra class and wondered &quot;what the heck is this useful for?&quot;. Well now you know.</p>
<p>Here's a two part video series with a concrete example that should give you a decent impression of what the real details look like:</p>
<p><a href="https://www.youtube.com/watch?v=aircAruvnKk" target="_blank">https://www.youtube.com/watch?v=aircAruvnKk</a></p>
<p><a href="https://www.youtube.com/watch?v=IHZwWFHWa-w" target="_blank">https://www.youtube.com/watch?v=IHZwWFHWa-w</a></p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/tomorrows_gone" target="_blank">tomorrows_gone</a>
			<div class="markdown"><p>3Blue1Brown is freaking amazing isn’t it!</p>
<p>Blows my mind how clear the explanations are whilst actually digging into the details. </p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Max_Rocketanski" target="_blank">Max_Rocketanski</a>
			<div class="markdown"><p>How much progress has been made in AGI?  How close are to duplicating the general intelligence of a young human or even a smart mammal like a dog?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/halborn" target="_blank">halborn</a>
			<div class="markdown"><p>I haven't been following things as closely as maybe I should have but the closest I'm aware of is DeepMind's AlphaZero which you can read about <a href="https://www.reddit.com/r/science/comments/a3r8l5/deepminds_alphazero_algorithm_taught_itself_to/" target="_blank">here</a>.  Long story short, it's roughly equivalent to WOPR from <em>WarGames</em>.  For a real idea of where the cutting edge is, you might like to ask in /r/askscience :)</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Senokir" target="_blank">Senokir</a>
			<div class="markdown"><p>While the advances in deep learning with the arrival of AlphaGo were substantial I would personally not put it in the category of working towards AGI in any other way. It may be the deep learning advances that help push us towards AGI, but AlphaGo is very much applied artificial intelligence.</p>
<p>I don't have sources off of the top of my head, but I believe that I have read about companies which are specifically working towards the development of AGI and I am sure they have come up with something much closer than AlphaGo since the goal of the projects are very much different. That being said, I don't think their work is public.</p>
<p>I say all of this as a lover of AI (and of Go!). AlphaGo will always be very special to me and is treated like a god in the Go community, but unfortunately it is not in any way AGI.</p>
<p>I will say though that once AlphaGo surpassed human ability at playing Go it played some moves which shocked the entire Go community. Moves which humans would have never dreamed of before. So much so that during the matches against Lee Sedol, which signaled the official end of humanity's superiority at the game of Go, the professionals and announcers thought on several occasions that there was a mistake. They thought that surely those were bad moves and that AlphaGo would never play anything that bad. It turns out that some of those moves AlphaGo defined as being extremely unlikely for a professional human to find (like 0.2%) but still thought that they looked good. It was our understanding that was flawed, not its. It is for this reason as well as some others that people who play AlphaGo have said that it feels as though it has true intuition and personality. It is not merely copying humans but went beyond human understanding to come up with moves of its own.</p>
<p>There is an excellent documentary called &quot;AlphaGo&quot; that I highly recommend to anyone that hasn't seen it.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/smc733" target="_blank">smc733</a>
			<div class="markdown"><p>Just don’t ask in /r/futurology if you want an accurate answer.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Iron_Pencil" target="_blank">Iron_Pencil</a>
			<div class="markdown"><p>You might want to check out &quot;unsupervised learning&quot; there are several examples of AIs playing explorative video games, by trying to always find new things in the game. Complicated video games are a possible avenue from specific AI to an AGI, due to requiring a generalizable problem solving capability. </p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/css123" target="_blank">css123</a>
			<div class="markdown"><p>I would say we are still far away. The closest thing we have are generative and adversarial networks in deep learning. These are able to come up with new insights by querying an internal approximation, or learning from another neural network (respectively). The internal representation that a deep network makes is called a latent variable, but it's important to remember that this latent variable, while hard to understand by people, is simply a statistical approximation of input data. The linearity of this approximation is related to how many layers are in the deep network. </p>
<p>This is where I think a lot of the &quot;buzz&quot; around deep learning comes from. The name can be misleading in that some many think of &quot;deep&quot; as deep insights into data, when it really is just describing the data structure of the network. </p>
<p>Neural networks are still quite finicky, a little delicate, and also sensitive to data with a large range and variance. They can be extremely powerful in recognizing non-linear relationships, but are poor at telling the programmer how these relationships are decided. A lot of the Data Science community still uses tried-and-true models like Random Forests and Gradient Boosting, but Neural Networks are A LOT better than they were in the 80s and 90s, and if we keep pace, we're going to see some great developments in the next couple decades.</p>
<p>Here is a great read on the subject: <a href="https://towardsdatascience.com/is-deep-learning-already-hitting-its-limitations-c81826082ac3" target="_blank">https://towardsdatascience.com/is-deep-learning-already-hitting-its-limitations-c81826082ac3</a></p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/MarkZist" target="_blank">MarkZist</a>
			<div class="markdown"><p>Great post, you seem to have a really good grasp of the material. A professor of mine once said that A.I. at its core is simply very advanced statistics. Do you agree with that idea? Or is it too simple?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/halborn" target="_blank">halborn</a>
			<div class="markdown"><p>Thanks :)  There's a great deal of truth to what your professor has said.  There is, of course, more to it than that but it's absolutely the case that a firm grasp of statistics is necessary if you want to be any good at ML/AI.  </p></div>		</li>
					</ul>
		</ul>
	
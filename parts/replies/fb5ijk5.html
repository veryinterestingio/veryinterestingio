	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/crispin1" target="_blank">crispin1</a>
			<div class="markdown"><p>Talking of quantum supremacy couldn't a 333 bit quantum computer count up to 10^100 things? One of Brassard's algorithms gives quadratic speedup for tasks such as computing the mean of n outputs of a function in O(sqrt n) which reduces the problem to 10^50. Still infeasible right now but less so.</p>
<p>Or use Shor's algorithm to factorize a 10000 digit number which may be feasible before long - then argue that classically you'd have had to count to a googol to do this.</p>
<p>Of course if you don't want a meaningful output then you could just set all your 333 qubits to zero, hadamard transform then do any computation at all, say, invert them. If you believe in many worlds you just did something a googol times with the catch that you never looked at the result. But this is of course scarcely better than your &quot;how many numbers are greater than a googol&quot; example.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/yifanlu" target="_blank">yifanlu</a>
			<div class="markdown"><p>Right it’s all about “counting results of a specific problem” vs “given an arbitrary problem count the results”. It’s a lot easier if you (the human) get to decide what’s being counted.</p>
<p>There’s also quantum algorithms for a handful of specific problems. And you can reframe some of these problems as “counting problems” (I think Grover’s search might work). There’s no general way to improve runtime NP problems with quantum computing though. I’m pretty sure there’s not even a general way to improve P problems.</p></div>		</li>
					</ul>
		</ul>
	
	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Monchoman45" target="_blank">Monchoman45</a>
			<div class="markdown"><p>To add to this: not every CPU or GPU manufactured is good. Often the second best chip available (eg. GTX 1070ti) is architecturally very similar or identical to the best chip available, but with minor defects. Rather than simply throwing that chip away entirely, they manually disable a few features and sell it at a discount. This means that often the reason the best chip is so expensive is because it's difficult to physically make one without any defects. Improvements in the manufacturing process - which may come from fields almost entirely unrelated to computers, like chemistry or physics - may make those chips significantly easier to produce, causing a price drop, and opening up a space in the market for a new high-power but difficult to produce chip.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/pheonixblade9" target="_blank">pheonixblade9</a>
			<div class="markdown"><p>This is called binning, and it happens because when you put billions of something in a single product, chances are some of those things will fail.</p>
<p>They figure out which bin to put each chip on a wafer into by doing something called post silicon validation - basically, run a bunch of tests on the chip.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/thebruce87m" target="_blank">thebruce87m</a>
			<div class="markdown"><p>We referred to that as “Final Test”. </p>
<p>Validation happened after the first silicon samples came out to make sure the silicon behaved as it was designed.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Electric_Ilya" target="_blank">Electric_Ilya</a>
			<div class="markdown"><p>If this is the case then surely there is deviation in the quality that is labeled top tier mid etc... How much deviation and real world performance difference is to be expected between identically sold chips?</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/cosmicosmo4" target="_blank">cosmicosmo4</a>
			<div class="markdown"><p>That's not what validation is. You're referring to test.</p>
<p><a href="https://en.wikipedia.org/wiki/Post-silicon_validation" target="_blank">Validation</a> is related to design, not manufacturing.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Pancake_Nom" target="_blank">Pancake_Nom</a>
			<div class="markdown"><p>It wasn't even always minor defects either - back when multi-core CPUs started gaining traction in the market, AMD sold a number of triple-core CPUs that were actually quad-core units with a defective core disabled.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/MasochistCoder" target="_blank">MasochistCoder</a>
			<div class="markdown"><p>later on when yields would improve, even the three-core models were proper four-core models with a perfectly functioning fourth core which you could reenable on some motherboards.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/marcan42" target="_blank">marcan42</a>
			<div class="markdown"><p>The defects are always minor, it's just that a single transistor failing inside a CPU core makes the entire CPU core useless. You can't sell a CPU that happens to not process some instructions properly. So you turn the whole core off.</p>
<p>The exception is memory, including caches. Often you can just disable a small portion of memory, or replace it with some spare memory available to cover for defects. This is the only reason Flash memory is affordable; all Flash used in SD cards, SSDs, etc has tons of defects, they just get marked as bad blocks and never used.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/grem75" target="_blank">grem75</a>
			<div class="markdown"><p>The first Celerons were Pentiums with failed cache.</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/US-person-1" target="_blank">US-person-1</a>
			<div class="markdown"><p>They should just make computers bigger, so they can fit more bits into it.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/PolarizedLenses" target="_blank">PolarizedLenses</a>
			<div class="markdown"><p>Although yes, memory storage and processing throughput would increase as you make components bigger, you would also increase power consumption (which <em>may</em> not be a big deal for personal computers but is a big deal for phones or huge servers) and increase delay/latency (which is bad for basically everyone).</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/running_on_empty" target="_blank">running_on_empty</a>
			<div class="markdown"><p>Imagine if they designed a computer that filled 64.8 cubic meters, across 1,800 square feet of space!? It would be a monster!</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/US-person-1" target="_blank">US-person-1</a>
			<div class="markdown"><p>sick, now just imagine if they designed one that was <em>twice</em> those dimensions</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Grakchawwaa" target="_blank">Grakchawwaa</a>
			<div class="markdown"><p>Even if it's a joke, I'll give it a serious ish answer. Unfortunately that would not be the case, as even nowadays physical distance on transistor circuits is often a significant factor as when we're working on nano-level (and probably on the larger scales as well) meaning that having to increase the surface area is actually a rather significant design loss and hurdle</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/bumblyburg" target="_blank">bumblyburg</a>
			<div class="markdown"><p>As a thermal engineer in the tech sector, this makes me cry.  Please stop.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/HotLaksa" target="_blank">HotLaksa</a>
			<div class="markdown"><p>The further electrons have to travel within a circuit, the slower the CPU. This is fine if all instructions can be done in parallel, but many operations have to be done in a certain order sequence. So smaller = faster.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Jitte" target="_blank">Jitte</a>
			<div class="markdown"><p>One step higher up the supply chain is ASML, an offshoot of Philips, which supplies the machines that create processors and the likes for Intel, TSMC, and Qualcomm. It's their EUV machine that is currently the state of the art, allowing for a higher density of transistors.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/skittlesdabawse" target="_blank">skittlesdabawse</a>
			<div class="markdown"><p>I suppose they also supply machines for &quot;smaller&quot; chip manufacturers like ST?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Jitte" target="_blank">Jitte</a>
			<div class="markdown"><p>I couldn't tell you, the industry from that part of the supply chain is pretty much business to business, so it's difficult to google-fu it.</p>
<p>I do know that AMD is the only big player to not get its machines from ASML, and Canon and Nikon are ASML's competitors in the market, with a marginal market share compared to it.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Always_two_more" target="_blank">Always_two_more</a>
			<div class="markdown"><p>ASML does have non euv machines that compete directly with nikon and canon etc.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/cosmicosmo4" target="_blank">cosmicosmo4</a>
			<div class="markdown"><p>ASML and like 100 other companies...</p>
<p>(Your post makes it sound like you would only find ASML tools in a fab)</p></div>		</li>
					</ul>
		</ul>
	
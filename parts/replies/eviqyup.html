	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/diamondketo" target="_blank">diamondketo</a>
			<div class="markdown"><p>Unfortunately what you're explaining sounds like a decision tree not a neural network. While there are characteristics in NN that uses decision trees, your eli5 misses how each neuron modifies itself to learn.</p>
<p>Even more your eli5 only explains when the NN is in its predicting stage not its learning stage.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/IrishJavaNerd" target="_blank">IrishJavaNerd</a>
			<div class="markdown"><p>I'd like to hear your ELI5 of this :)</p>
<p>(sounds sarcastic but I don't mean it that way)</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Odd_B" target="_blank">Odd_B</a>
			<div class="markdown"><p>Sounds like Boolean theorem</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/WadeEffingWilson" target="_blank">WadeEffingWilson</a>
			<div class="markdown"><p>I think that you might be able to bridge the gap by adding that the NN goes through a training period by taking in a set of normalized data and iterating through it numerous times where it adjusts variables called weights and bias. </p>
<p>Once that phase is complete, you can test it out operationally and determine its accuracy. If it's low, it can be run again with more iterations (or less, so as to avoid overfitting) or with a better sample data set with which to be taught.</p>
<p>There are so many algorithms for activation functions (what is used to determine the probability output), numerous models, frameworks, and types of capabilities that it would go beyond the scope of ELI5.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/[deleted]" target="_blank">[deleted]</a>
			<div class="markdown"><p>[gel√∂scht]</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/MyWholeSelf" target="_blank">MyWholeSelf</a>
			<div class="markdown"><p>In short, our little brains are crazy efficient.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Jim_Panzee" target="_blank">Jim_Panzee</a>
			<div class="markdown"><p>Excuse me if I'm wrong, but I think this is not how a NN is trained. You are describing genetic algorithms and not back propagation. Or am I missing something?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/grm42" target="_blank">grm42</a>
			<div class="markdown"><p>Correct, back propagation is the traditional way to train NNs. GA is also possible.</p>
<p>I'm not an expert in the field, but I currently work in a project where a persom smarter than me is using GAs to train NNs. That is why I had GA in mind.</p>
<p>I'll edit my comment and add that I'm just explaining one way to train it.</p>
<p>How would you ELI5 back propagation? A teacher checks if the building came to the correct conclusion, and, if not, goes trough all the rooms and scolds everybody who messed up?</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/sponge_bob_" target="_blank">sponge_bob_</a>
			<div class="markdown"><p>Natural selection for machines?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/TheVoidSeeker" target="_blank">TheVoidSeeker</a>
			<div class="markdown"><p><a href="https://en.wikipedia.org/wiki/Genetic_algorithm" target="_blank">Genetic algorithms</a></p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/DoctorWho14k" target="_blank">DoctorWho14k</a>
			<div class="markdown"><p>Thanks!! This makes a lot of sense!</p></div>		</li>
					</ul>
	
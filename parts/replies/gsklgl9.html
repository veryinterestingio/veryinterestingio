	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/eltommonator" target="_blank">eltommonator</a>
			<div class="markdown"><p>So how do you know if a std deviation is high or low? I don't have a concept of what a large or small std deviation &quot;feels&quot; like as I do for other things, say, measures of distance.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ForceBru" target="_blank">ForceBru</a>
			<div class="markdown"><p>I don't think there's a universal notion of large or small standard deviation because it depends on the scale of your data.</p>
<p>If you're measuring something small, like the length of an ant, an std of 0.5 cm could be large because, let's say, 0.5 cm is the length of a whole ant.</p>
<p>However, if you're measuring people and get an std of 0.5 cm, then it's really small since compared to a human's height, 0.5 cm is basically nothing.</p>
<p>The coefficient of variation (standard deviation divided by mean) is a dimensionless number, so you could, loosely speaking, compare coefficients of variation of all kinds of data (there are certain pitfalls, though, so it's not a silver bullet).</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/PureRandomness529" target="_blank">PureRandomness529</a>
			<div class="markdown"><p>I think your last paragraph encapsulates what they were asking. It’s not a standard deviation of 0.5cm, that’s too specific without enough context. It’s a standard deviation of x% of the mean, and that determines the “size” of the standard deviation.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/nosradom" target="_blank">nosradom</a>
			<div class="markdown"><p>One way might be to compare the standard deviation to the precision of your measurements. If you are measuring to the nearest inch a STD of .5 inches is really low. However if you are measuring to the nearest .0001 inches a STD of .5 inches is really high (or you are measuring more precise than needed).</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/KillerOkie" target="_blank">KillerOkie</a>
			<div class="markdown"><blockquote>
<p>If you're measuring something small, like the length of an ant, an std of 0.5 cm could be large because, let's say, 0.5 cm is the length of a whole ant.</p>
</blockquote>
<p>There is some chonky girls in that data pool.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/batataqw89" target="_blank">batataqw89</a>
			<div class="markdown"><p>Std deviation retains the same units as the data, so you might get a std deviation of 10cm for people's heights, for example. Then you'd roughly expect that the average person is 10cm away from the mean in one direction of another.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/niciolas" target="_blank">niciolas</a>
			<div class="markdown"><p>That’s why in some applications is useful to consider the so called <em>Coefficient of variation</em>, that measure is calculated as the ratio between the standard deviation and the average of a given set of observations.</p>
<p>This measure gives you the percentage of deviation with respect to the mean value.</p>
<p>This is sometimes more explicable, though as someone else has pointed out, the nature of the data collected and the phenomenon analyzed is really important in judging whether a standard deviation is high or not.</p>
<p>Expert judgement of the topic analyzed is what matter, the measures are just an instrument!!</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/computo2000" target="_blank">computo2000</a>
			<div class="markdown"><p>What would those advantages be? I learned about variance some years ago and I still can't figure out why it should have more theoretical (or practical) uses than MAD.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/sliverino" target="_blank">sliverino</a>
			<div class="markdown"><p>For starters, we know the distribution of the squares of the errors when the underlying data is Gaussian, it's a Chi Square!
This is used to build all those tests and confidence intervals.
In general, sum of squares will be differentiable, absolute value is not continuously differentiable.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/forresja" target="_blank">forresja</a>
			<div class="markdown"><p>Uh. Eli don't have a degree in statistics</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/AmonJuulii" target="_blank">AmonJuulii</a>
			<div class="markdown"><p>MAD is generally easier to explain and in some areas it's widely used as a measure of variation.<br />
Mean square deviation (= variance = S.D^(2)) tends to &quot;punish&quot; outliers, meaning that abnormally high or low values in a sample will increase the MSD more than they increase the MAD, and this is often desired.<br />
A particularly useful property of mean square deviation is that squaring is a smooth function, but the absolute value is not. This lets us use the tools of calculus (which have issues with non-smooth functions) to develop statistical models.<br />
For instance, linear regression models are fitted by the 'least squares' method: minimising the sum of squared errors. This requires calculus.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/wattnurt" target="_blank">wattnurt</a>
			<div class="markdown"><p>IMO the simplicity of the formula and its differentiability are literally <strong>the</strong> reasons for its popularity, because the nonlinearity of it is actually rather problematic.</p>
<blockquote>
<p>meaning that abnormally high or low values in a sample will increase the MSD more than they increase the MAD, and this is often desired.  </p>
</blockquote>
<p>I don't know what field you are in, but the undue sensitivity to outliers is problematic in any of the fields I am familiar with. It often requires all kinds of awkward preprocessing steps to eliminate those data points.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/kaihatsusha" target="_blank">kaihatsusha</a>
			<div class="markdown"><p>Do you go to the pizza store which is average but predictable every time, or do you go to the pizza store which is raw 1/3 of the time, and burnt 1/3 of the time?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/wagon_ear" target="_blank">wagon_ear</a>
			<div class="markdown"><p>OK good analogy, but any measure of variability of data would tell you that, and the person above you was asking why standard deviation was superior to something like mean absolute deviation</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Don_Cheech" target="_blank">Don_Cheech</a>
			<div class="markdown"><p>This explanation is the one that helped remind me of what the term meant. Thanks</p></div>		</li>
					</ul>
	
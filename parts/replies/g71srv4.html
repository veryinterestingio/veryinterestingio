	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/esaltz" target="_blank">esaltz</a>
			<div class="markdown"><p>Thanks for this question. You’ve hit on a lot of the core questions in this field!</p>
<p>First, 1. What recommendations would you make to social media platforms to combat misinformation?</p>
<p>While I’m wary to offer too many blanket, specific design recommendations for platforms with very different UX/UI designs (i.e. an algorithmic feed like Instagram may need very different interventions from a video platform like YouTube or a closed messaging group on WhatsApp or Slack), in our post <a href="https://medium.com/swlh/it-matters-how-platforms-label-manipulated-media-here-are-12-principles-designers-should-follow-438b76546078" target="_blank">on design principles for labeling</a> we try to summarize some of the first design principles that we believe apply across platforms when it comes to contextual labels, such as “Offer flexible access to more information” and “Be transparent about the limitations of the label and provide a way to contest it.” But of course labels are just one way to address misinformation: other approaches include removal, downranking, or general digital literacy and <a href="https://misinforeview.hks.harvard.edu/article/global-vaccination-badnews/" target="_blank">prebunking</a> interventions that are all worth considering in concert, and carefully studying and understanding how people respond. In terms of the technological infrastructure for rating misinformation, in a <a href="https://medium.com/partnership-on-ai/5-urgent-considerations-for-the-automated-categorization-of-manipulated-media-8fad982b2db0" target="_blank">recent blog about automated media categorization</a>, we raise many specific recommendations, including more transparent and robust ways of thinking about harms of information on platforms, and prioritizing the grounded insights of local fact-checkers and affected communities.</p>
<p>If I had to summarize my recommendations more generally in a few words it would be: transparency, oversight, and accountability. The Santa Clara Principles on Transparency and Accountability in Content Moderation (<a href="https://santaclaraprinciples.org/" target="_blank">numbers, notice, and appeals</a>) summarize these recommendations well.</p>
<p>For 2. What existing laws require changing or new laws implemented to combat misinformation?</p>
<p>While we’re not policy experts, legislators internationally are taking many different approaches to mis/disinformation and hate speech issues <a href="https://www.brookings.edu/blog/techtank/2020/06/17/online-content-moderation-lessons-from-outside-the-u-s/" target="_blank"><a href="https://www.brookings.edu/blog/techtank/2020/06/17/online-content-moderation-lessons-from-outside-the-u-s/" target="_blank">https://www.brookings.edu/blog/techtank/2020/06/17/online-content-moderation-lessons-from-outside-the-u-s/</a></a> and manipulated media such as “deepfakes” <a href="https://www.theguardian.com/us-news/2019/oct/07/california-makes-deepfake-videos-illegal-but-law-may-be-hard-to-enforce" target="_blank"><a href="https://www.theguardian.com/us-news/2019/oct/07/california-makes-deepfake-videos-illegal-but-law-may-be-hard-to-enforce" target="_blank">https://www.theguardian.com/us-news/2019/oct/07/california-makes-deepfake-videos-illegal-but-law-may-be-hard-to-enforce</a></a></p>
<p>Finally for 3. What can individuals do to combat misinformation?</p>
<p>Slow down, and question your own emotional response to the information you see and where it came from! Try to understand the underlying dynamics at play, and when and where you might expect more mis- and disinformation to appear, such as on topic areas where there are gaps in information. To get a better grounded sense of mis and disinformation in its many forms, I recommend studying past examples, such as <a href="https://www.buzzfeednews.com/article/janelytvynenko/coronavirus-fake-news-disinformation-rumors-hoaxes" target="_blank"><a href="https://www.buzzfeednews.com/article/janelytvynenko/coronavirus-fake-news-disinformation-rumors-hoaxes" target="_blank">https://www.buzzfeednews.com/article/janelytvynenko/coronavirus-fake-news-disinformation-rumors-hoaxes</a></a>. Talk to your friends and family to better understand their information consumption habits, what they trust, and why.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/victoriakwan" target="_blank">victoriakwan</a>
			<div class="markdown"><p>To add to Emily's excellent answers for Question 1 about platforms:</p>
<ol>
<li>I would love to see platforms employ more visual cues to help viewers quickly distinguish between different types of posts in our feeds. Right now, when I go to Facebook or to YouTube, the content all looks very similar as I scroll through, whether it's an update from a fact checker, photos of a cousin's pet, a post from a public health organization, or a conspiracy theory video. To help an overloaded (or even just distracted) brain figure out the credibility of the information, platforms should consider <a href="http://flanagin.faculty.comm.ucsb.edu/CV/Metzger%26Flanagin%2C2013%28JoP%29.pdf" target="_blank">adding</a> <a href="http://flanagin.faculty.comm.ucsb.edu/CV/MetzgerandFlanagin2015(HPCT).pdf" target="_blank">heuristics</a>.</li>
</ol></div>		</li>
					</ul>
	
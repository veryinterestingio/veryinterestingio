	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/jbreeding28" target="_blank">jbreeding28</a>
			<div class="markdown"><p>On another note, CPUs have gotten much better at threading and parallelizing workloads in recent years. It used to be that in order to get more computing power, you needed to up the clock speed. Now you can add cores and do other optimizations so that you can get more power without having to increase clock speed. At this point in time it's easier to just add more power that way than to find cooling solutions to allow for increased clock speeds.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Garaleth" target="_blank">Garaleth</a>
			<div class="markdown"><p>Now only if software can catch up and properly utilise multi-threading.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/FireFerretDann" target="_blank">FireFerretDann</a>
			<div class="markdown"><blockquote>
<p>Lol</p>
</blockquote>
<ul>
<li>Programmers everywhere</li>
</ul></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/danielstaleiny" target="_blank">danielstaleiny</a>
			<div class="markdown"><p>functional programming ftw</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Vanniv_iv" target="_blank">Vanniv_iv</a>
			<div class="markdown"><p>Tools for developing asynchronous software are improving, bit it still is far away from good enough -- it is easy to make multi-threaded software (though not all problems are easily divided), but it is still extremely difficult to debug broken multi-threaded software.  This means that good, highly-asynchronous software costs a ton to develop.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/grumpysysadmin" target="_blank">grumpysysadmin</a>
			<div class="markdown"><p>Sadly, one of the optimizations you mentioned is what led to the whole class of CPU vulnerabilities such as <a href="https://en.wikipedia.org/wiki/Spectre_(security_vulnerability)" target="_blank">Spectre and Meltdown</a> which means that in the past 6 months, if you are keeping your OS and BIOS up to date, computers have been getting <em>slower</em> as those features have been disabled or fixed with more secure but slower firmware updates. </p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/YaBoyMax" target="_blank">YaBoyMax</a>
			<div class="markdown"><p>It's important to note that parallelization in this context refers also to instruction-level parallelization, which occurs automatically at the hardware level.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/chateau86" target="_blank">chateau86</a>
			<div class="markdown"><p>That's how you get 31-stage pipeline a la Prescott.</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/s9oons" target="_blank">s9oons</a>
			<div class="markdown"><p>Another note on this, the 7nm architecture currently utilized is actually the smallest realistically possible using current FinFET (Fin field effect transistors) designs. Going down to 5nm (the next IRDS 2017 roadmap scheduled step) I believe requires going to  gallium-arsenide (GaAs) and/or GAAFETs (gate-all-around field effect transistors) to mitigate the quantum tunneling effects that happen when using Silicon/FinFETs at that scale. 5nm is scheduled for \~2020, but as far as I know TSMC (Taiwan Semiconductor Manufacturing Company) is still developing the 5nm production process. They did, however, break ground on Fab 18 (their new manufacturing facility for 5nm &amp; 3nm) January of 2018. </p>
<p>&#x200B;</p>
<p>\&nbsp;</p>
<p>&#x200B;</p>
<p>The ELI5 answer is basically that we've gotten to the production scale where you have to start considering &amp; mitigating quantum effects which get... complicated... </p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Altmao" target="_blank">Altmao</a>
			<div class="markdown"><blockquote>
<p>their new manufacturing facility for 5nm &amp; 3nm</p>
</blockquote>
<p><a href="/applegasp" target="_blank"></a>Hold up. <em>Three</em> nanometers now?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/JustifiedParanoia" target="_blank">JustifiedParanoia</a>
			<div class="markdown"><p>yup, and there are supposed single proof-concept transistors in the labs of 1nm and below, heading towards being no more than a few atoms.....</p>
<p>the hard part is not making individual transistors, its making them work together, and making billions work at the same time, and doing it cheaply.</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/imonmyphoneirl" target="_blank">imonmyphoneirl</a>
			<div class="markdown"><p>What about using light instead of electricity...yes this is a serious question, generally curious about why we aren't using light</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Solohman" target="_blank">Solohman</a>
			<div class="markdown"><p>My guess would be that the photodiodes and photoreceptors (at least the ones I've personally seen) are pretty hefty compared to just a normal wire. We'd need to find ways to severely reduce those in side while maintaining the reliability needed.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Shitsnack69" target="_blank">Shitsnack69</a>
			<div class="markdown"><p>Their response is also much slower due to stray capacitance.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/RuruTutu" target="_blank">RuruTutu</a>
			<div class="markdown"><p>Light doesn't change things and persist in the same way electrons and electricity does. It could maybe be possible someday, but it would be the same kind of leap as from mechanical computing to electronic.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Yancy_Farnesworth" target="_blank">Yancy_Farnesworth</a>
			<div class="markdown"><p>Because the speed of electricity through a copper wire (which is the material electricity goes through in microchips) is almost the same as the speed of light (2.8 million m/s vs 3 million m/s). And we don't have a light equivalent of a transistor that we can make at such small scales as the silicon/copper ones we have now.</p></div>		</li>
					</ul>
		</ul>
	
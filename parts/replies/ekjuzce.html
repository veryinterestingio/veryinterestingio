	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/wisequokka" target="_blank">wisequokka</a>
			<div class="markdown"><p>We collected around 4.5 petabytes of data during the 2017 EHT campaign.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/PM_ME_UR_ASS_GIRLS" target="_blank">PM_ME_UR_ASS_GIRLS</a>
			<div class="markdown"><p>Did you guys actually go through every bit of data, or were there specific/important parts you focused on to get the end result (a picture)? If so, now that you've announced your findings to the public, will you be going over the data more thoroughly and is there anything else to learn from this data, or is your focus on the next experiment/step?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/illiriya" target="_blank">illiriya</a>
			<div class="markdown"><p>They used algorithms. This video by one of the members explains it very well</p>
<p><a href="https://www.ted.com/talks/katie_bouman_what_does_a_black_hole_look_like/up-next?language=en" target="_blank">https://www.ted.com/talks/katie_bouman_what_does_a_black_hole_look_like/up-next?language=en</a></p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ColorUserPro" target="_blank">ColorUserPro</a>
			<div class="markdown"><p>Holy hell. How are you able to compile anything of meaning off of that much raw data?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/YaYathahitta" target="_blank">YaYathahitta</a>
			<div class="markdown"><p>Algorithms can scan through and put together the meaningful bits I would assume</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/TheNorthComesWithMe" target="_blank">TheNorthComesWithMe</a>
			<div class="markdown"><p>As far as I understand the final image was reconstructed from a very small amount of data. What happened to the rest of the 4.5 petabytes?</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/wisdom_possibly" target="_blank">wisdom_possibly</a>
			<div class="markdown"><p>Did you have backups?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/mjanssen-eht" target="_blank">mjanssen-eht</a>
			<div class="markdown"><p>No, we were gambling ;)</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/wisequokka" target="_blank">wisequokka</a>
			<div class="markdown"><p>stop revealing our secrets Michael!</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/1solate" target="_blank">1solate</a>
			<div class="markdown"><p>Really? Why?</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/lindyblackburn" target="_blank">lindyblackburn</a>
			<div class="markdown"><p>Great question! It would be too costly to back up all the 4.5 PB of raw signal data from the telescopes, but as we are measuring the average correlation between signals at different sites, a small amount of lost data (from a single failed hard drive for example) can simply be excluded from the average without impacting the result. Once the data are correlated and averaged (a factor of a million reduction in data volume), they are backed up in many ways.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ErikTheAngry" target="_blank">ErikTheAngry</a>
			<div class="markdown"><p>Speaking to the cost of the backups of raw data, broadly speaking, how would they relate to the cost of reproducing said lost data in the event of a catastrophic data loss?</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/boredcircuits" target="_blank">boredcircuits</a>
			<div class="markdown"><p>The final result has certainly been &quot;backed up&quot; across the internet today!</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/lindyblackburn" target="_blank">lindyblackburn</a>
			<div class="markdown"><p>Some VLBI networks do use the internet to send their data to a central location. This is difficult for the EHT because:</p>
<p>1) The EHT records at a very high bandwidth</p>
<p>2) The EHT uses telescopes at very high (remote) sites to avoid as much water vapor as possible. These are not always equipped with fast internet connections and even transferring a few seconds of data over the internet for a quick check can be difficult.</p>
<p>As of 2018, the EHT records at 64 Gigabits per second at each telescope. This is probably a couple orders of magnitude above what is reasonable for electronic transfer from even well-equipped sites.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/rustyrocky" target="_blank">rustyrocky</a>
			<div class="markdown"><p>So modern satellites are basically just ornaments on top of huge data centers these days, pretty amazing to think about. </p>
<p>(No surprise, but still it is pretty crazy.)</p></div>		</li>
					</ul>
		</ul>
	
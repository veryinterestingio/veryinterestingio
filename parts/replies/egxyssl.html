	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/dranobob" target="_blank">dranobob</a>
			<div class="markdown"><p>This is the correct answer. It’s true heat and standardization are factors, but the main driving force is that size reduction comes with unnecessary added costs. </p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Istartedthewar" target="_blank">Istartedthewar</a>
			<div class="markdown"><p>Heat on memory isn't an issue anymore whatsoever, DDR4 uses so little power the heatsinks on them are really only for aesthetics.  DDR2 was the last era heatspreaders on ram really did anything.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/spritanium" target="_blank">spritanium</a>
			<div class="markdown"><p>Remember RAM coolers? Lol</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Clovis69" target="_blank">Clovis69</a>
			<div class="markdown"><p>The machine we are building at work has liquid cooling to the RAM...</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Year_of_the_Alpaca" target="_blank">Year_of_the_Alpaca</a>
			<div class="markdown"><blockquote>
<p>DDR4 uses so little power the heatsinks on them are really only for aesthetics.</p>
</blockquote>
<p>Aw, c'mon. You're not telling me that the shiny, brightly-coloured whizz bang heat spreaders on several-times-the-regular-price gaming PC RAM is just to make them look shiny and cool and justify their inflated price?!</p>
<p>Next you'll be saying that the glowy RGB LEDs attached to the top of it serve no useful purpose!</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/sblvguy" target="_blank">sblvguy</a>
			<div class="markdown"><p>To add, even though denser chips exist and the size of a 32GB stick and the 16GB stick are the same, you can use downgraded chips that marginally failed. For example, in processing, you find some 2GB chips only have a working capacity of 1GB, we can populate the stick with those binned ones and churn out a return on those instead of just throwing then away. </p>
<p>This is common on CPUs where some of the cores aren't fully functional and so they market it as the next product down in the list. Some frugal over clockers try to take advantage of this and try to use the disabled cores to gain extra processing power. Or they used to, I'm not sure if it's still a thing</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/nalc" target="_blank">nalc</a>
			<div class="markdown"><p>I am not sure I agree - if you look at how the memory modules are created, it's the same either way. You're on the same 14nm lithography processes and the silicon is the same. What's different is the packaging. And that's more about legacy standards and heat management than it is about cost. The chip itself in a desktop processor isn't actually any bigger than the equivalent chip in a laptop processor, but it's got a larger heatspreader and fits in a larger socket and has a larger heatsink for better thermal management and because space is less of a constraint. RAM slots have been roughly the same length for decades - the memory chips aren't necessarily any smaller in laptop RAM, but it's packaged into a smaller form factor. I've seen reviews where they opened up 2.5&quot; SSDs (which are really only 2.5&quot; because that was an existing magnetic hard drive format) and the 128GB, 256GB, and 512GB are all the same circuit board, which only takes up half the enclosure anyway.  A 256GB SSD might be eight 32GB modules while the 128GB is four 32GB modules, it is more efficient for them to make one size chip and just use more or less of them. </p>
<p>In certain applications it is indeed cheaper to go with more modules of less storage density, but it's not a universal truth and in many cases the form factors are determined by legacy standards than anything else. </p>
<p>Edit - I'm also curious, if you've got, say, 1GB versus 2GB individual RAM chips, both on the same lithography, how are they different? Are the smaller sizes just binned from the larger sizes (i.e. a 2GB chip with flaws that mean half the silicon is defective?) or are they actually designed differently? </p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/dranobob" target="_blank">dranobob</a>
			<div class="markdown"><p>If it’s not about cost, then why not reduce the size with each new iteration of DDR?  </p>
<p>DDR4 is not backwards compatible with DDR3, DDR2, etc. so keeping a similar size form factor has no standardization benefit. </p>
<p>And laptop ram has always cost more than desktop because it costs more to cram the same chips onto a smaller form factor. </p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/steak4take" target="_blank">steak4take</a>
			<div class="markdown"><p>That's really not true.  Phone RAM is the exact same configuration and technology as low powered laptop RAM - DDR3LP.  In many cases phones even use the same chips.  DDR3LP is small by design because it uses less power.  The price difference is just profiteering by some manufacturers because there's no real competition beyond 4-6 models.  Compare that to the literal hundreds of PC RAM manufacturers and their variety of products from bare bones, to low profile, Value offerings and gamer targeted RGB lit packages.</p>
<p>Phone board design is a well refined and pretty cheap process now - we've been at it for two decades and more.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/marcan42" target="_blank">marcan42</a>
			<div class="markdown"><p>You're mixing up DDR3L (low power desktops, servers and laptops) with LPDDR3 (phones, really low power ultraportables/tablets and certain MacBooks). DDR3L is just normal DDR3 running at a lower voltage, but LPDDR3 is a completely different and incompatible technology. LPDDR3 is only available as raw chips to be soldered down, not as exchangeable modules (DIMM/SODIMM).</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/steak4take" target="_blank">steak4take</a>
			<div class="markdown"><p>I'm only mixing them up in name. There are quite a few Ultrabooks with LPDDR3.  And aside from bus cards, the difference between LPDDR3 and DDR3L (and standard for that matter) is where the interposer resides in the chipset.  They are not a &quot;completely different&quot; technology.  All three RAM standards are derived from the same technology - double data rate RAM, that's why the chipsets are also largely compatible too.  From a manufacturing perspective LPDDR3 is actually cheaper to make than sticks of RAM because it's a single process involving only one part.  From an assembly perspective LPDDR3 is more expensive because there are fewer suppliers. That's all.</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/jerzeypipedreamz" target="_blank">jerzeypipedreamz</a>
			<div class="markdown"><p>Its also important to remember the smaller the device the slower it runs due to keeping the heat down. You can have a desktop and a laptop with the same exact numbers when it comes to ram, gpu, processors and the desktop will outperform the laptop every time by almost 1/3 because the laptop has to run under heat constraints. So to try and fit all that power into a phone and without a cooling fan they have drop the power considerably to keep the phone from getting 200 degrees.</p></div>		</li>
					</ul>
	
	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/[deleted]" target="_blank">[deleted]</a>
			<div class="markdown"><p>[entfernt]</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/kayson" target="_blank">kayson</a>
			<div class="markdown"><p>This is not really an issue. Buffers are added throughout clock distribution networks to keep the clock signals &quot;square&quot;. This is necessary even at much lower frequencies than the fastest CPUs.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/GruevyYoh" target="_blank">GruevyYoh</a>
			<div class="markdown"><p>The way I understand this stuff is the higher the slew rate of the signal, the more current is being dissipated - because every circuit has non zero capacitance and resistance. </p>
<p>The heat generated by higher frequencies becomes problematic, because you're charging that capacitance more quickly, needing more current and therefore more heat. </p>
<p>The slew rate vs current vs heat vs frequency race is probably almost over, so we have to go massively parallel. Unless we can brilliantly come up with room temperature superconductivity and ultralow capacitance. Silicon may not be good enough, we'll need new materials. </p>
<p>So we're pretty much halting at 64 bit CPUs, but now way more CPUs per die. The new NVidia ARM thing with 192 cores is exactly this. The clock speed per core isn't particularly high. This was true 20 years ago of the Sun Microsystems SPARC chips too. 1 ghz x 16 cores, IIRC, when Intel had 4 ghz but only 1 core.</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/kayson" target="_blank">kayson</a>
			<div class="markdown"><p>I don't think we're anywhere close to the limitation of timing circuits as far as a CPU goes. Balanced clock trees, among other techniques, are used to address the challenge of distributing the clock to different parts of the core at the same time. Since CPUs are pipelined, you also have some margin in when the clock needs to arrive. Granted, some of that is eaten up by other factors. But consider that an RTX 2080 TI runs its memory at 14Gbps (using a 7GHz DDR clock), so there's an entire clock domain within the GPU running at that frequency. We could definitely see much higher speeds in CPUs, but in the current software design paradigm, there's not really a huge need.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/[deleted]" target="_blank">[deleted]</a>
			<div class="markdown"><p>[entfernt]</p></div>		</li>
					</ul>
	
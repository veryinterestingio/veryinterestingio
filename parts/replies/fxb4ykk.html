	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ImissCBB" target="_blank">ImissCBB</a>
			<div class="markdown"><p>Interesting! So for the lossy factor, does resolution even matter? Meaning, wouldn’t a 4K resolution video with high lossy rate be worse than a 1080p vide with a low lossy rate?</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Xelopheris" target="_blank">Xelopheris</a>
			<div class="markdown"><p>The thing with the lossiness is that it is still about predicting specific pixels. The more pixels you have, the more detail it needs. The algorithm will produce an exact number of pixels to fit the resolution it was compressed for.</p>
<p>When you take a 4k video that is lossy, you still produce a 4k resolution worth of pixels. The only thing that changes is the accuracy of those pixels to the original pixel in the raw footage.</p>
<p>It is possible to make an algorithm so lossy that it would look worse than a higher-detailed 1080p video, but most major algorithms don't actually have that much range in them.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ImprovedPersonality" target="_blank">ImprovedPersonality</a>
			<div class="markdown"><p>I think it very much depends on the specific video. For example highly (lossy) compressed video of movement usually looks like garbage. Half the resolution (i.e. a quarter of the pixels) with less compression can easily look better while requiring much less space (or bandwidth) and processing power.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/Unique_username1" target="_blank">Unique_username1</a>
			<div class="markdown"><p>Not necessarily.</p>
<p>There are ongoing improvements in using a small amount of data to store higher quality video.</p>
<p>A lot of modern video formats (for streaming) will not include data for parts of the video that don’t change, or if an object moves but does not change, it will describe the movement but only describes the object once.</p>
<p>It takes a lot of processing power to “rebuild” the video from these descriptions, but you can reproduce the video in good detail without an amount of data anywhere <em>close</em> to 30 full quality images per second. </p>
<p>Newer devices have specialized parts of the processor dedicated to playing back video efficiently which is why an older computer that is powerful in some ways may struggle to play back YouTube or Netflix, while a newer phone that isn’t as powerful as a desktop computer will play back those videos perfectly.</p>
<p>In other words the trade off doesn’t need to be smaller size for less quality, but if you want smaller size without loss of quality your device does need to support the newer technologies to achieve this. Blu-ray Discs are not <em>always</em> better quality video than a streamed video, but they can be played back on a cheaper device. Not a huge advantage now, but back when blu-ray came out, the tricks we use to make a 4K Netflix video so small would not have been affordable or even available in a simple DVD player type device.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/JCDU" target="_blank">JCDU</a>
			<div class="markdown"><p><a href="https://www.youtube.com/results?search_query=tom+scott+video+compression" target="_blank"><a href="https://www.youtube.com/results?search\_query=tom+scott+video+compression" target="_blank">https://www.youtube.com/results?search\_query=tom+scott+video+compression</a></a></p>
<p>The different methods used can achieve better or worse quality for the same total file size.</p>
<p>Old stuff like MJPEG is literally a series of JPEG's stacked together. H.264 uses some very clever methods (and a lot of maths) to do all sorts of stuff like working out which parts of an image have moved and just recording that information, so rather than drawing a new picture of a car every frame it'll just say &quot;this big red blob moved 10 pixels to the left&quot;, &quot;oooh it did it again&quot;, &quot;oooh it went 20 pixels this time&quot;, etc.</p>
<p>The newer/smarter algorithms are also very carefully tuned to what the human eye notices and what it doesn't - the luminance data (brightness) is encoded at a higher resolution than the colours (think colouring in a high-res black &amp; white photo with a fat brush) and not all colours get equal information due to our eye's sensitivity to some more than others.</p>
<p>Even boring old still JPEG is bad at encoding blue, because it was developed for photos where blue is usually sky and hence we don't care nearly as much about detail in blue as reds and greens.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/saulstari" target="_blank">saulstari</a>
			<div class="markdown"><p>h266</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ImissCBB" target="_blank">ImissCBB</a>
			<div class="markdown"><p>That’s actually what prompted this question haha. Realized how little I know about this topic. Some awesome answers here</p></div>		</li>
					</ul>
		</ul>
	
	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/xenneract" target="_blank">xenneract</a>
			<div class="markdown"><p>This is close to what my thinking was, and I was surprised that I haven't been able to find anything like that online. Which made me also wonder if I was missing the point of how to evaluate model quality.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/captainhaddock" target="_blank">captainhaddock</a>
			<div class="markdown"><p>Data scientist Youyang Gu (<a href="https://twitter.com/youyanggu" target="_blank">https://twitter.com/youyanggu</a>) has been posting some comparisons like that â€” particularly to show how useless the IHME model has been. He's identified five models that <em>have</em> made better predictions than the baseline as well.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/mr4ffe" target="_blank">mr4ffe</a>
			<div class="markdown"><p><a href="https://twitter.com/youyanggu/status/1275490419271512067?s=19" target="_blank">Here's</a> that Tweet.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/qleap42" target="_blank">qleap42</a>
			<div class="markdown"><p>There are other ways but it all comes down to how well the model does compared to the actual data. The same method is used to test climate models. There are some climate models that try to assume very little and then see how well they can predict the past 20 years using just data from more than 20 years ago. Then using the calibrated model try to predict the next 20 years.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/CyberPlatypus" target="_blank">CyberPlatypus</a>
			<div class="markdown"><p>That's actually how particle physics simulations work, which I think is kind of neat. When physicists are designing particle detectors, they use software to model how well the detector works and the sort of data we should expect from it. The model is usually good, but not perfect. Then when we actually build the detector, we see what the detector <em>actually</em> measures, and we make the necessary changes to the modeling software to make it more accurate. Then we use the updated modeling software to make even better detectors, and you just keep on going in that cycle.</p>
<p>I assume that this sort of cycle is pretty commonplace.</p></div>		</li>
						<li class="reply">
			<a class="author" href="https://www.reddit.com/user/jack0s" target="_blank">jack0s</a>
			<div class="markdown"><p>You mean they feed data for the period, say, 1920-1940, check the results for the next decades and compare with the real numbers?</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/whadupbuttercup" target="_blank">whadupbuttercup</a>
			<div class="markdown"><p>You can also run into real issue w/r/t interpretability. For instance, the team I work with has a model that will predict future confirmed cases within about 5% more than half the time which is exceptionally good considering the frequency, noise, and behavioural issues at play.</p>
<p>That being said, the model itself is an unsupervised one, which is to say, not something where the structure is defined by the statistician. As a consequence, backing out specific effects can be quite hard - so the question becomes &quot;What use is it to know how many COVID-19 cases will there be in a county in Texas in August but nothing else?&quot; and the answer is &quot;not a whole lot&quot;.</p></div>		</li>
					</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/ValidatingUsername" target="_blank">ValidatingUsername</a>
			<div class="markdown"><p>It's also important to factor in the response capabilities and actions taken by the countries to really appreciate the predictions made by scientists.</p>
<p>Flatten the curve and shutting down society fundamentally changed what variables one can use to paramaterize their models.</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/[deleted]" target="_blank">[deleted]</a>
			<div class="markdown"><p>[entfernt]</p></div>		</li>
					<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/[deleted]" target="_blank">[deleted]</a>
			<div class="markdown"><p>[entfernt]</p></div>		</li>
					</ul>
		</ul>
			<li class="reply">
			<a class="author" href="https://www.reddit.com/user/xenneract" target="_blank">xenneract</a>
			<div class="markdown"><p><a href="https://viz.covid19forecasthub.org/" target="_blank">This tool</a> seems to be the closest to that kind of information for the Covid models that I've managed to find.</p></div>		</li>
					</ul>
	
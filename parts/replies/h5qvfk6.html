	<ul class="replies">
		<li class="reply">
			<a class="author" href="https://www.reddit.com/user/UCSF_official" target="_blank">UCSF_official</a>
			<div class="markdown"><p>Hi, we are doing well! We appreciate the community giving us this opportunity to answer some questions about our work! I'll try to answer your questions in order:</p>
<ol>
<li>It is definitely very interesting to apply machine learning to the analysis of brain activity! There are many research labs doing this for a variety of topics. One common theme of this application of machine learning is the relative scarcity of data: To train artificial neural networks (ANNs) to recognize people in images, interpret sound waves into text, program autonomous vehicles, etc., researchers and engineers often have access to millions of training examples. When working with brain data, you often have many, many fewer examples. In our work, we had less than 10,000 total examples that we could use (each example is one attempt by the participant to produce one of the words) to train our ANN to perform word classification from neural activity. To overcome this challenge, we employed techniques such as time jittering and data augmentation, which we describe in more detail in the Supplementary Appendix accompanying our publication.</li>
<li>Also in our Supplementary Appendix, we have a figure showing the relationship between word classification accuracy and training data quantity. It seems that after about 4 hours of training data, word classification accuracy was around 40% (random chance of accuracy is 2%).</li>
<li>There are certainly hiccups that come up in a project of this magnitude! Honestly, a major obstacle for us was the COVID-19 pandemic, which necessitated we pause our sessions with the participant to adhere to university policies. Thankfully, our participant stayed safe throughout this time period, so we consider ourselves relatively lucky!</li>
<li>This is a great question, and there is definitely some evidence to suggest that this is possible to an extent. This concept is known in the field as &quot;transfer learning&quot;, where knowledge/model parameters can be transferred from one scenario to a slightly different one. Here, this can be from one person to another. Right now, we see that some model parameters can be learned using data from multiple participants, but some parameters of the model do best when they are learned using data from individual participants. In our lab, we have published some of these findings in a previous paper that involved participants who could speak (<a href="https://www.nature.com/articles/s41593-020-0608-8" target="_blank"><a href="https://www.nature.com/articles/s41593-020-0608-8" target="_blank">https://www.nature.com/articles/s41593-020-0608-8</a></a>).</li>
</ol>
<p>We are looking forward to assessing this in the future with more clinical trial participants who are unable to speak!</p>
<p>-DAM</p></div>		</li>
					</ul>
	
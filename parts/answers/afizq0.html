<div class="answers">
	<div class="answer" data-handle="edz2gxv">
		<a class="author" href="https://www.reddit.com/user/halborn" target="_blank">halborn</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>In the interest of sticking to the spirit of ELI5, I'm gonna gloss over some really interesting and complicated things.  If anyone has questions or wants greater detail, feel free to ask.  </p>
<hr />
<p>Since it's kind of an inherent property of computers that any computer can run any software, the development of AI is a programming exercise rather than an engineering one.  In order to understand what kind of programs may be AI, we first need to ask what AI <em>is</em>.  </p>
<p>In the perception of the general public there are essentially two categories of AI, one of which exists and one of which does not.  The latter is the kind of AI you see in science fiction movies like <em>Terminator</em>, <em>Eagle Eye</em> and <em>Blade Runner</em>.  We call this <em>artificial general intelligence</em>; AI which can perform general intelligent action (like humans and other animals do) or perhaps even experience a kind of consciousness.  The former is the kind of AI you see in software, websites and other applications such as self-driving cars, virtual assistants and those face-changing cellphone apps.  We call this <em>applied artificial intelligence</em>; AI for studying specific datasets, solving specific problems or performing specific tasks.  In general, you can expect that the continued development of applied AI will lead to the eventual emergence of AGI.<br />
The distinguishing mark of the kinds of problems we use applied AI to solve is that they are problems which previously we would call on a human (or at least an animal) to solve.  For a long time, human drivers, living assistants and human artists are how we would accomplish solutions to the problem examples I mentioned above.  Meanwhile, the natural strength of computers is in calculation alone.  While humans could do all sorts of things computers could not, computers could perform calculation much more quickly and accurately than humans can.  Thus, there was division between man and machine.  </p>
<p>I hope all that context wasn't too boring because I'm about to get to an important point.  Now that we understand what AI is, we can rephrase OP's question in a way which gives us insight into the answer.  Instead of &quot;how is AI possible&quot;, we ask this: <strong>how can we make computers good at doing the things that people can do?</strong>  And the answer, of course, is in finding ways to mathematically describe the problems that humans solve by means such as instinct and practice.  If we can come up with a way to describe human problems with numbers then we can use the computational strength of machines to solve those problems.  Thus the endeavour of AI programmers is all about collecting, understanding, framing and processing data.  It's about forgetting how a human sees a problem for long enough to boil it down to sheer numbers that a machine can work with and then returning to a human frame of mind so that the meaning behind those numbers is not lost.  </p>
<p>This leaves the question of how, exactly, it is done and I suppose the best way to answer is with a simple example.  For those who want to <strong>TL;DR</strong> past the bulk of this comment, here's where to jump in.<br />
Imagine you want to write a program for telling red things apart from blue things.  First, you're going to need to collect some pictures of red things and blue things and then you're going to label each of them with the correct colour.  You feed this information to the computer.  Now, digital images are stored as lists of numbers.  Each pixel has a value for how red (R), how green (G) and how blue (B) it should be displayed.  The computer can see that the images labelled &quot;red&quot; tend to have pixels with high values for R and low values for B while the images labelled &quot;blue&quot; tend to have pixels with high values for B and low values for R.  It can also see that the value of G just doesn't seem to matter much.  At this stage, the program has a rudimentary understanding of the labels &quot;red&quot; and &quot;blue&quot; as they relate to the pixel content of an image.  Now you can show it a new image and ask it whether the image belongs to the &quot;red&quot; set or the &quot;blue&quot; set and the computer will look at the pixels, do some math, and tell you whether the image has high R values or high B values.  The more images you use to train the computer with, the better it will understand the difference and the better a job it can do of telling red and blue apart in new images.  </p>
<hr />
<p>Hopefully this helps.  Chances are I've missed out something important so please feel free to ask me questions or for greater detail on any point.  It's really an interesting topic and it's certainly the direction of the future.  </p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<a class="less-answers upper" href="javascript:void(0)">less answers...</a>
	<div class="answer" data-handle="edyz0ow">
		<a class="author" href="https://www.reddit.com/user/aragorn18" target="_blank">aragorn18</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>First, it's important to understand that AI is a lot of different things all wrapped up under one category.</p>
<p>Most of what we call AI is just software (or code as you put it). There is hardware that will accelerate the kinds of calculations that this code requires but the chip itself would not be considered the AI.</p>
<p>Two common approaches to AI are neural networks and genetic algorithms. Neural networks are an attempt to recreate the way the brain works by having multiple nodes between the input and the output and the program will build connections between those nodes. The connection and strength of that connection will determine what the output is. This is a loose approximation of what the brain does when it learns.</p>
<p>Genetic algorithms are a way for a system to get better over time. You start with a population of individual programs that are basically random in their configuration and then you test them on whatever task you are attempting to perform. Most of them will be awful because they're just acting randomly but 1 or 2 might be slightly better than random. </p>
<p>You take the best examples from the first generation and slightly mutate their configuration until you have a second population. Then you test them and hopefully some of these mutations were beneficial and you have 1 or 2 that are better than the best from the 1st generation. </p>
<p>Keep doing this over and over and eventually you might end up with a program that can do the task you want without ever directly programming it how to do that task.</p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="edz1c9m">
		<a class="author" href="https://www.reddit.com/user/Rainelz-" target="_blank">Rainelz-</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>“AI is whatever hasn’t been done yet” stated Larry Tesler in 1980.
AI has been coupled with different technologies during the years.</p>
<p>Currently, we are facing the problem with a set of techniques implemented in software. One of the most hyped and, since 2010, common technique is deep learning, which for sake of simplicity we will refer to as neural networks.</p>
<p>A neural network is a set of connected nodes, called neurons, which takes a numerical (multidimensional) vector input and outputs one or more values.
Each node basically applies a mathematical transformation (e.g. multiplication) to the input with respect to a weight (multiplication factor) and see whether the result activated or not the considered neuron, propagating the result to the next node.</p>
<p>Why deep learning? Because we are facing problems by creating very deep neural networks and training them on known data (a lot of data) to predict values when fed with unseen data.
The learning process consists in adjusting the aforementioned weights (factors) to obtain the known result given the known input.</p>
<p>The are plenty of operations that a node can perform, defining different network architectures. There are evidences that some architectures work better on certain problems and worse on others.
So right now, imo, AI is a architecture definition + data collection problem.</p></div>		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="edz80kr">
		<a class="author" href="https://www.reddit.com/user/quickcrow" target="_blank">quickcrow</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>The most important thing is that AI is a misleading name. It would be FAR more accurate but a lot less sexy to call it &quot;Improved Pattern Recognition&quot;. </p></div>		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="edz6ftx">
		<a class="author" href="https://www.reddit.com/user/SignalToNoiseRatio" target="_blank">SignalToNoiseRatio</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>There are different kinds of AI. “Expert Systems” have been around a while and they’re usually pieces of software that use “if-this-then-that” logic. Machine learning is another popular AI technique. If you wanted to make an app that could tell the difference between a picture of a cat, or a dog, you would input thousands of examples labeled “cat” or “dog”. Then, the software’s core processing routing (“the algorithm”) would “learn” to tell the difference.</p>
<p>A popular “learning” algorithm is a neural network. Think of it as layer upon layer of simple software image filters. The top layer might recognize edges in the image, the the next layer might recognize the difference between edges that are cat-like vs edges that are dog-like, and at the end of the process, after the image has been filtered through all of these layers, the computer gives a “score” of how likely it is the image is a cat or a dog.</p>
<p>It might be clear now that the better the example images you use, the better your software (“the model”) is. Gathering high-quality examples is one of the hardest parts of AI!</p>
<p>Now, when you give the software a new image it’s never seen before, it can filter it through the neural network and get a score. For instance, it’s 90% likely that this is a picture of a cat.</p>
<p>The software can be written in one of many languages. Printing the software routines onto a chip doesn’t really change the way the software works other than it makes it faster.</p></div>		<div class="replies-placeholder"></div>
	</div>
</div>
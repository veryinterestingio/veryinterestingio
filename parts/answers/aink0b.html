<div class="answers">
	<div class="answer" data-handle="eep376j">
		<a class="author" href="https://www.reddit.com/user/Rannasha" target="_blank">Rannasha</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>The basis of digital video formats is still a sequence of still images, just like analogue film.</p>
<p>However, for efficiency purposes, various optimizations are made, because storing a full resolution still image for every single frame would require a large amount of storage space (and a large amount of bandwidth to transfer).</p>
<p>The main way that digital video optimizes storage requirements is by not storing each frame as a full still image. Instead, a frame will only contain the differences between that frame and the previous. For most video clips large parts of the scene remain unchanged between two consecutive frames, which allows the next frame to be constructed using a relatively small amount of data.</p>
<p>In order to facilitate actions like forwarding and rewinding through a video, a &quot;key frame&quot; is inserted at regular intervals. Key frames contain the full image rather than only the differences between two frames. That way it's possible to start playback at a different point than the start of the video without having to first reconstruct the entire set of frames leading up to the selected starting point.</p>
<p>There are various techniques that further optimize the tradeoff between storage, quality and processing power needed, but the basic idea remains the same: Just like with analogue video, digital video still consists of individual frames that are recorded, stored and played sequentially.</p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<a class="less-answers upper" href="javascript:void(0)">less answers...</a>
	<div class="answer" data-handle="eep9fly">
		<a class="author" href="https://www.reddit.com/user/haplo_and_dogs" target="_blank">haplo_and_dogs</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>When doing a professional recording for the movie industry where you have a much much larger budget studios will actually use a format that is basically identical to &quot;moving pictures.&quot;  With space as not a limitation you can record raw, which means that you save every frame independent of all other frames as a picture with a timecode.</p>
<p>This is about 3Gigs per min of recording at just 1080p, and a shocking 12 Gigs per min at 4k.</p>
<p>This is often used because it allows easier and faster editing with no artifacts from compression.  Re-editing compressed footage will always introduce new artifacts if the compression isn't lossless.
Some pro-sumer cameras allow this as well, however you need to be careful to make sure your storage medium is up to scratch to use them, as the data coming out can exceed the write speed of many standard SD cards!</p>
<p>Movies would never be delivered to customers in this faction as at 1080p a Blue ray would hold less than 10 minuets of video!  </p></div>		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="eepa3rw">
		<a class="author" href="https://www.reddit.com/user/StreamingEagle" target="_blank">StreamingEagle</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>Video expert here. Digital video is a sequence of pictures (frames).  Video can be uncompressed (for example, a sequence of uncompressed TIF images is commonly used by professionals for storing movies), losslessly compressed (there are lossless modes for JPEG-2000, H.264, H.265), or encoded with lossy compression (most video that consumers shoot or watch).   When professionals refer to film or video, we're mostly referring to the way the content was captured (was it with a film camera, as movies were captured for many years, or was it with a video camera?).  Movies shot on film are converted to video by scanning each frame of film (a process that is also known as Telecine... <a href="https://en.wikipedia.org/wiki/Telecine" target="_blank"><a href="https://en.wikipedia.org/wiki/Telecine" target="_blank">https://en.wikipedia.org/wiki/Telecine</a></a>).  That's because it all ends up as digital video these days, but filmed content has a different look, and different qualities (like film grain) than video captured with video cameras.  </p>
<p>When you say &quot;Analogue Recording&quot;, you were probably referring to filmed movies... but the first video cameras were analog, not digital.  They stored a continuous analog signal on magnetic tape.   </p>
<p>With respect to lossy digital video compression, other comments here have referred to the fact that most frames (P and B frames) of video (except the &quot;key frames&quot;... or more accurately, the I frames) are coded with the difference between blocks of pixels in the current frame versus preceding or subsequent frames.  That's called &quot;inter-prediction&quot;; the first part of encoding most of the frames of a video.  The next part is to determine the &quot;residual error&quot; after prediction (by subtracting the predicted frame from the source frame), and then to encode some of this residual error. First the residual error is transformed from the spatial domain into the frequency domain, usually by using a Discrete Cosine Transform, then the least significant frequencies in the residual error are &quot;quantized&quot; away... but sometimes if the predicted block is good enough, and the residual error is small, no residual error is coded.  After prediction and residual error are coded, the whole digital bitstream is further compressed (losslessly) with something like CABAC compression.</p></div>		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="eep8tof">
		<a class="author" href="https://www.reddit.com/user/sqrrl101" target="_blank">sqrrl101</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>The other commenters are correct that digital video is usually stored and distributed in a compressed format, but it's worth noting that many professional-grade cameras will output in a &quot;RAW&quot; format. This means that the camera system is storing each image separately in a manner that's pretty directly analogous to video recorded on analogue film, with every pixel of every frame being defined without compression algorithms. Doing this requires far more storage space - each second of 1080p resolution, 60-fps RAW video takes up <a href="https://en.wikipedia.org/wiki/Uncompressed_video" target="_blank">2.98 Gbit of space</a>, meaning that an hour of that video would be around 1.3 TB. Recording like this makes it easier to edit the footage, but is completely infeasible for most consumer-grade equipment to store and play, and increases the bandwidth required to transmit it by a factor of \~1,000.</p>
<p>Please note, I'm not at all an expert in video recording/editing, so I don't know how common this is - I'd assume that most films and TV shows that are recording digitally and need lots of editing record in RAW, but can't be confident about that.</p>
<p>Edit: This account is somewhat misleading, check the comments below for a more accurate idea of what's going on.</p></div>		<div class="replies-controls">
			<a class="show-replies" href="javascript:void(0)">show replies...</a>
			<a class="hide-replies" href="javascript:void(0)">hide replies...</a>
		</div>
		<div class="replies-placeholder"></div>
	</div>
	<div class="answer" data-handle="eeq3bii">
		<a class="author" href="https://www.reddit.com/user/sawdeanz" target="_blank">sawdeanz</a>
		<span class="qa" title="Answer">A:</span><div class="markdown"><p>Yes and no. You may already be aware that TVs/Monitors work differently than a film projector. A film projector advances a strip with still images very fast, with a shutter to facilitate showing each image individually without a blur. A monitor instead receives a continuous data stream which tells it how to change each pixel progressively, starting from the top to the bottom of the screen. A full cycle of changing all the pixels from top to bottom is a scan (you may have heard of progressive vs interlaced video, this is what this involves). </p>
<p>Now with regards to movies, it is still captured and displayed as a series of frames (for purposes of editing, pausing, etc.) The pixels are all displayed to create one full image, and then after a period of time (say 1/24th a second for a film) the pixels are refreshed with the colors of the next frame. But the monitor doesn't see the whole image at once like a projector does, it is a continuous data stream that just happens to be divided into subsets of frames. The monitor scans many times a second, typically 120 times compared to just 24 or 30 frames per second for a video, so the monitor is basically repeating each frame several times relative to it's scan rate.</p>
<p>Recording video is similar. There is a sensor that is exposed to light and converts it into a digital value for each pixel in the same progressive manner. In lower end video cameras this operation can sometimes be observed if there is a camera/lighting flash. Half of the sensor records the bright light but by the time the info is read off the second half the light is gone giving you a frame that is half bright and half dark. The cameras that filmmakers use are called digital-film cameras to differentiate them from an older video camera. These high-end film cameras have shutters and capture each frame as an independent photo file, like a digital camera. </p></div>		<div class="replies-placeholder"></div>
	</div>
</div>